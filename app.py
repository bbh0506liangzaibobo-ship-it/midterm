import streamlit as st
import tempfile
import os
from langchain_groq import ChatGroq
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.chains.retrieval_qa.base import RetrievalQA
from langchain_community.document_loaders import PyPDFLoader, TextLoader

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "history" not in st.session_state:
    st.session_state.history = []
if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = None

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="RAG ì±—ë´‡ - ì¤‘ê°„ê³ ì‚¬ í”„ë¡œì íŠ¸",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ëª¨ë¸ ì´ˆê¸°í™”
@st.cache_resource
def load_models():
    # API í‚¤ë¥¼ ì§ì ‘ ì½”ë“œì— ì‘ì„±
    groq_api_key = "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"
    
    llm = ChatGroq(
        model="llama-3.1-8b-instant",
        api_key=groq_api_key,
        temperature=0.1
    )
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    return llm, embeddings

def process_uploaded_file(uploaded_file):
    """ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name
    
    try:
        # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ë¡œë” ì„ íƒ
        if uploaded_file.name.endswith('.pdf'):
            loader = PyPDFLoader(tmp_file_path)
        else:
            loader = TextLoader(tmp_file_path, encoding='utf-8')
        
        documents = loader.load()
        
        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        texts = text_splitter.split_documents(documents)
        
        return texts
    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(tmp_file_path):
            os.unlink(tmp_file_path)

def main():
    st.title("ğŸ¤– RAG ì±—ë´‡ - ì¤‘ê°„ê³ ì‚¬ í”„ë¡œì íŠ¸")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” - íŒŒì¼ ì—…ë¡œë“œ
    with st.sidebar:
        st.header("ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader(
            "TXT ë˜ëŠ” PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['txt', 'pdf'],
            help="ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ í•´ë‹¹ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤."
        )
        
        if uploaded_file and st.button("ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘"):
            with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                try:
                    llm, embeddings = load_models()
                    texts = process_uploaded_file(uploaded_file)
                    
                    if texts:
                        # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
                        st.session_state.vectorstore = Chroma.from_documents(
                            documents=texts,
                            embedding=embeddings
                        )
                        
                        # RAG ì²´ì¸ ìƒì„±
                        st.session_state.qa_chain = RetrievalQA.from_chain_type(
                            llm=llm,
                            chain_type="stuff",
                            retriever=st.session_state.vectorstore.as_retriever(search_kwargs={"k": 3}),
                            return_source_documents=True
                        )
                        
                        st.success(f"âœ… ë¬¸ì„œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ({len(texts)}ê°œì˜ í…ìŠ¤íŠ¸ ì¡°ê°)")
                        st.session_state.history.append({
                            'role': 'assistant',
                            'content': f'ë¬¸ì„œ "{uploaded_file.name}"ì´(ê°€) ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!'
                        })
                    else:
                        st.error("âŒ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    st.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        st.markdown("---")
        st.info("""
        **ğŸ“‹ ì‚¬ìš© ë°©ë²•:**
        1. ì™¼ìª½ì—ì„œ ë¬¸ì„œ íŒŒì¼ ì—…ë¡œë“œ
        2. 'ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘' ë²„íŠ¼ í´ë¦­
        3. ì•„ë˜ ì±„íŒ…ì°½ì—ì„œ ì§ˆë¬¸ ì…ë ¥
        4. AIê°€ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ ì œê³µ
        
        **ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ:**
        - **Langchain**: RAG ì‹œìŠ¤í…œ êµ¬ì¶•
        - **Groq API**: ê³ ì† AI ëª¨ë¸
        - **ChromaDB**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
        - **Streamlit**: ì›¹ ì¸í„°í˜ì´ìŠ¤
        """)
        
        # í˜„ì¬ ìƒíƒœ í‘œì‹œ
        st.markdown("---")
        st.subheader("ì‹œìŠ¤í…œ ìƒíƒœ")
        if st.session_state.qa_chain:
            st.success("âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
        else:
            st.warning("âš ï¸ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")

    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    st.subheader("ğŸ’¬ ë¬¸ì„œ ì§ˆì˜ ì‘ë‹µ")
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for msg in st.session_state.history:
        with st.chat_message(msg['role']):
            st.markdown(msg['content'])
    
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input("ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ì§ˆë¬¸í•´ë³´ì„¸ìš”...")
    
    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
        st.session_state.history.append({
            'role': 'user',
            'content': user_input
        })
        
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # ì‘ë‹µ ìƒì„±
        if st.session_state.qa_chain:
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    try:
                        result = st.session_state.qa_chain.invoke({"query": user_input})
                        
                        # ì‘ë‹µ í‘œì‹œ
                        response_text = result["result"]
                        st.markdown(response_text)
                        
                        # ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
                        st.session_state.history.append({
                            'role': 'assistant',
                            'content': response_text
                        })
                        
                        # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
                        with st.expander("ğŸ” ì°¸ê³  ë¬¸ì„œ ë³´ê¸°"):
                            st.write("ë‹¤ìŒ ë¬¸ì„œ ì¡°ê°ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤:")
                            for i, doc in enumerate(result["source_documents"]):
                                st.markdown(f"**ì°¸ê³  {i+1}:**")
                                st.text(doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content)
                                st.caption(f"ì¶œì²˜: {doc.metadata.get('source', 'Unknown')}")
                                st.markdown("---")
                                
                    except Exception as e:
                        error_msg = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        st.error(error_msg)
                        st.session_state.history.append({
                            'role': 'assistant',
                            'content': error_msg
                        })
        else:
            warning_msg = "âš ï¸ ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”!"
            st.warning(warning_msg)
            st.session_state.history.append({
                'role': 'assistant',
                'content': warning_msg
            })

    # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
    if st.session_state.history and st.sidebar.button("ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°"):
        st.session_state.history = []
        st.rerun()

    # í‘¸í„°
    st.markdown("---")
    st.caption("ì¤‘ê°„ê³ ì‚¬ í”„ë¡œì íŠ¸ - Langchain RAG ì±—ë´‡ | Streamlit Cloud ë°°í¬")

if __name__ == "__main__":

    main()

